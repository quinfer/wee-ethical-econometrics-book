{
  "hash": "9c475ee27a8a67bc065abeb28edb8ef1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Causal Salad, Endogeneity and collider bias\"\nauthor: \"Barry Quinn\"\neditor: visual\n---\n\n\n\n\n\n\n\n\n\n\n\\![\\](images/DALLÂ·E 2024-01-29 16.56.33 - A humorous and illustrative image depicting the concept of \"causal salad\" in linear regression modeling. The scene is set in a chaotic kitchen, where .png)\n\n## Perils of Causal Salad in Econometric Analysis\n\nIn the realm of econometric analysis, a prevalent pitfall is the creation of what can be colloquially termed a \"causal salad.\" This term refers to the misguided practice of indiscriminately adding more predictors to a model, often without adequate theoretical justification or understanding of the underlying causal relationships. This approach can lead to models that are overfitted, misinterpreted, and ultimately misleading.\n\nA common manifestation of this issue is the practice of blindly incorporating a variety of predictors into a model and then presenting these additions as some form of robustness test. While robustness checks are essential in econometrics to ensure that results are not an artifact of specific model specifications, the unprincipled expansion of the model with additional predictors can do more harm than good. It often leads to false confidence in the model's findings and obscures the true relationships between variables.\n\nThis indiscriminate approach ignores the crucial need for a model to be grounded in a solid theoretical framework. Without a clear understanding of the potential causal pathways and the role of each variable, adding more predictors can introduce biases, such as endogeneity and collider bias, rather than alleviate them. These biases can significantly distort the estimates and lead to erroneous conclusions, particularly in complex fields like finance where the stakes are high.\n\nIn this chapter, we will explore the concepts of endogeneity and collider bias in depth, demonstrating how they arise and their implications in econometric models. We will particularly focus on real-world finance examples to illustrate these concepts and discuss strategies to avoid the pitfalls of causal salad through careful model specification and robustness testing.\n\n## Introduction to Endogeneity\n\nEndogeneity is a crucial concept in econometrics, referring to situations where an explanatory variable is correlated with the error term. This correlation can stem from omitted variables, measurement errors, or simultaneity issues in the model. Endogeneity leads to biased and inconsistent estimates, making it challenging to deduce the true effects of explanatory variables on the dependent variable. Endogeneity, a critical issue in econometric analysis, can manifest in several main ways, significantly affecting the validity and interpretation of regression results. Understanding these manifestations is crucial for choosing appropriate methods to address them. Here are the primary forms of endogeneity:\n\n### 1. Simultaneity (Simultaneous Equations Bias)\n\n**Scenario:** This occurs when the dependent variable and one or more independent variables are mutually determined. For example, in a supply and demand model, both supply and demand depend on the price and quantity, making them simultaneously determined. **Real-World Example:** In finance, simultaneity often occurs in the relationship between a company's investment decisions and its stock performance. A firm's investment can influence its stock price, but simultaneously, the market's valuation of the firm can affect its investment capabilities.\n\n**R Simulation:**\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nn <- 1000\ninvestment_shock <- rnorm(n)\nstock_performance_shock <- rnorm(n)\nstock_price <- 2 + 0.5 * investment_shock - 0.5 * stock_performance_shock\ninvestment <- 2 + 0.3 * stock_price + investment_shock\n\n# Regression without considering simultaneity\nmodel <- lm(investment ~ stock_price)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = investment ~ stock_price)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.51291 -0.51686  0.00869  0.46892  2.48394 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.06837    0.07244   0.944    0.345    \nstock_price  1.28033    0.03452  37.095   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7378 on 998 degrees of freedom\nMultiple R-squared:  0.5796,\tAdjusted R-squared:  0.5792 \nF-statistic:  1376 on 1 and 998 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n### 2. Omitted Variable Bias\n\n**Scenario:** This happens when a model misses out on an important variable that is correlated with both the dependent and an independent variable. The omitted variable's effect is then wrongly attributed to the included variables, leading to biased estimates. **Real-World Example:** When estimating the impact of macroeconomic indicators on stock market returns, omitting relevant variables like political stability or international market trends can lead to biased estimates.\n\n**R Simulation:**\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nn <- 1000\neconomic_indicator <- rnorm(n)\npolitical_stability <- rnorm(n)  # Omitted variable\nstock_returns <- 1 + 2 * economic_indicator + 3 * political_stability + rnorm(n)\n\n# Regression without the omitted variable\nmodel <- lm(stock_returns ~ economic_indicator)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = stock_returns ~ economic_indicator)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.7261  -2.2906   0.0117   2.1686  10.8766 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          1.1033     0.1012   10.90   <2e-16 ***\neconomic_indicator   2.2451     0.1021   21.99   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.2 on 998 degrees of freedom\nMultiple R-squared:  0.3264,\tAdjusted R-squared:  0.3257 \nF-statistic: 483.6 on 1 and 998 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n### 3. Measurement Error\n\n**Scenario:** When variables are measured inaccurately, this measurement error can lead to endogeneity. This is especially problematic if the measurement error is not random but systematically related to the true value or other variables in the model. **Real-World Example:** If financial analysts use mismeasured or approximated figures for a company's earnings (due to accounting discrepancies), this can lead to incorrect inferences about the company's financial health.\n\n**R Simulation:**\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nn <- 1000\ntrue_earnings <- rnorm(n)\nmeasurement_error <- rnorm(n, sd = 0.5)\nobserved_earnings <- true_earnings + measurement_error\nstock_price <- 1 + 2 * true_earnings + rnorm(n)\n\n# Regression with observed earnings\nmodel <- lm(stock_price ~ observed_earnings)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = stock_price ~ observed_earnings)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.5889 -0.8497 -0.0049  0.8982  4.1774 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        0.95440    0.04067   23.47   <2e-16 ***\nobserved_earnings  1.54565    0.03533   43.74   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.285 on 998 degrees of freedom\nMultiple R-squared:  0.6572,\tAdjusted R-squared:  0.6569 \nF-statistic:  1914 on 1 and 998 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n### 4. Self-Selection\n\n**Scenario:** Self-selection bias arises in observational data when the sample is not randomly selected but determined by the characteristics of the individuals or entities. For example, if individuals select themselves into a treatment based on characteristics that also affect the outcome, this can lead to biased estimates of the treatment effect. **Real-World Example:** In a study of the performance of mutual funds, if fund managers self-select into certain investment strategies based on unobserved skills, this could bias the estimated effect of these strategies on fund performance.\n\n**R Simulation:**\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nn <- 1000\nmanager_skill <- rnorm(n)\nstrategy <- ifelse(manager_skill > 0, 1, 0)  # High skill managers choose a certain strategy\nfund_performance <- 1 + 2 * manager_skill + 3 * strategy + rnorm(n)\n\n# Regression without considering self-selection\nmodel <- lm(fund_performance ~ strategy)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = fund_performance ~ strategy)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.1758 -1.0677 -0.0817  1.1015  5.8937 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -0.5887     0.0723  -8.142 1.15e-15 ***\nstrategy      6.2938     0.1017  61.862  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.609 on 998 degrees of freedom\nMultiple R-squared:  0.7932,\tAdjusted R-squared:  0.7929 \nF-statistic:  3827 on 1 and 998 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n### 5. Reverse Causality\n\n**Scenario:** This occurs when the direction of causality between the independent and dependent variables is unclear or bi-directional. For instance, higher income might lead to better health outcomes, but at the same time, better health could lead to higher income, creating a reverse causality issue. **Real-World Example:** Considering the relationship between corporate borrowing and profitability, higher profitability might lead to more borrowing due to increased creditworthiness, but at the same time, more borrowing can lead to higher profitability due to increased investment capacity.\n\n**R Simulation:**\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nn <- 1000\nprofitability <- rnorm(n)\nborrowing <- 2 * profitability + rnorm(n)  # borrowing influenced by profitability\n\n# Regression of borrowing on profitability\nmodel <- lm(borrowing ~ profitability)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = borrowing ~ profitability)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0279 -0.6914  0.0043  0.7087  3.2911 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    0.04105    0.03183    1.29    0.198    \nprofitability  2.08805    0.03211   65.03   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.006 on 998 degrees of freedom\nMultiple R-squared:  0.8091,\tAdjusted R-squared:  0.8089 \nF-statistic:  4229 on 1 and 998 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n### 5. Error in variables\n\n**Scenario**: This is a specific type of measurement error where the error is in the independent variables. It can lead to biased and inconsistent parameter estimates. A scenario where the residuals from one regression are used in a subsequent regression is an example of error in variables. This is a common issue in finance where analysts might use estimated variables (like residuals from a regression) as predictors in further analyses, without realizing that these estimates carry their own error terms.\n\n### Real-World Example:\n\nIn finance, this could occur when an analyst first regresses a company's stock returns on certain economic indicators to estimate \"unexplained returns\" (residuals). These residuals, which are supposed to represent the portion of returns not explained by economic indicators, might then be used in a subsequent regression to examine other factors, like investor sentiment. However, since these residuals contain estimation errors, using them as predictors in a new regression can lead to biased results.\n\n### R Simulation:\n\nFirst, we'll run a regression to obtain residuals, and then use these residuals in a subsequent regression.\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# First Regression: Stock Returns on Economic Indicators\nset.seed(123)\nn <- 1000\neconomic_indicators <- rnorm(n)\nstock_returns <- 1.5 + 2 * economic_indicators + rnorm(n)\nfirst_model <- lm(stock_returns ~ economic_indicators)\nresiduals_from_first <- residuals(first_model)\n\n# Second Regression: Using Residuals as Predictor\ninvestor_sentiment <- rnorm(n)\nsecond_model <- lm(residuals_from_first ~ investor_sentiment)\nsummary(second_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = residuals_from_first ~ investor_sentiment)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9805 -0.6842  0.0078  0.6866  3.2665 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)\n(Intercept)        0.0005848  0.0318190   0.018    0.985\ninvestor_sentiment 0.0290768  0.0325323   0.894    0.372\n\nResidual standard error: 1.006 on 998 degrees of freedom\nMultiple R-squared:  0.0007998,\tAdjusted R-squared:  -0.0002014 \nF-statistic: 0.7988 on 1 and 998 DF,  p-value: 0.3717\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\nIn this simulation, the second regression uses residuals (unexplained returns) from the first regression as the dependent variable and examines their relationship with investor sentiment. However, since these residuals contain estimation errors from the first regression, the results of the second regression could be biased or misleading.\n\nThis example underscores the importance of understanding the properties of variables used in regressions, especially when they are derived from previous estimations. It's essential to account for potential errors and biases introduced in such scenarios.\n\n::: callout-important\nEach R simulation provides a basic model to illustrate how these endogeneity issues might manifest in financial data. In practice, more sophisticated models and techniques would be employed to identify and correct for these issues, such as instrumental variable regression, fixed effects models, or structural equation modeling.\n:::\n\n\\## R simulations\n\n### 1. Simultaneity (Simultaneous Equations Bias)\n\nIn simultaneous equations models, there is a mutual dependence among the explanatory variables and the response variable. We'll simulate a simple supply and demand model where both supply and demand depend on price, but price is also determined by supply and demand.\n\n``` r\n# Load necessary library\nlibrary(stats)\n\n# Simulate data\nset.seed(0)\nn <- 1000\ndemand_shock <- rnorm(n, 0, 1)\nsupply_shock <- rnorm(n, 0, 1)\nprice <- 2 + 0.5 * demand_shock - 0.5 * supply_shock\nquantity <- 2 + 0.3 * price + demand_shock\n\n# Run regression without considering simultaneity\nmodel <- lm(quantity ~ price)\nsummary(model)\n```\n\n### 2. Omitted Variable Bias\n\nOmitting an essential variable leads to biased estimates of the remaining variables. Let's look at a simulation representing this situation.\n\n``` r\n# Simulate data with an omitted variable\nset.seed(0)\nn <- 1000\nx1 <- rnorm(n, 0, 1)\nx2 <- rnorm(n, 0, 1)  # An omitted variable\ny <- 1 + 2 * x1 + 3 * x2 + rnorm(n, 0, 1)\n\n# Perform regression excluding the second variable\nmodel <- lm(y ~ x1)\nsummary(model)\n```\n\n### 3. Measurement Error\n\nMeasurement errors introduce incorrect information about independent variables, resulting in erroneous parameter estimates. Let's examine a simulation demonstrating this concept.\n\n``` r\n# Simulate data with measurement error\nset.seed(0)\nn <- 1000\nx_true <- rnorm(n, 0, 1)\nmeasurement_error <- rnorm(n, 0, 0.5)\nx_measured <- x_true + measurement_error\ny <- 1 + 2 * x_true + rnorm(n, 0, 1)\n\n# Conduct regression with measured data\nmodel <- lm(y ~ x_measured)\nsummary(model)\n```\n\n### 4. Self-Selection\n\nIndividuals voluntarily participating in programs based on certain traits creates selection bias. Now, let's explore a scenario involving self-selection.\n\n``` r\n# Simulate data with self-selection\nset.seed(0)\nn <- 1000\nability <- rnorm(n, 0, 1)\ntreatment <- (ability > 0) + 0L  # Individuals with higher abilities opt for treatment\ny <- 1 + 2 * ability + 3 * treatment + rnorm(n, 0, 1)\n\n# Execute regression ignoring self-selection\nmodel <- lm(y ~ treatment)\nsummary(model)\n```\n\n### 5. Reverse Causality\n\nHere, we simulate scenarios where determining the direction of causality becomes challenging.\n\n``` r\n# Simulate data with reverse causality\nset.seed(0)\nn <- 1000\ny <- rnorm(n, 0, 1)\nx <- 2 * y + rnorm(n, 0, 1)\n\n# Carry out regression assuming wrong causality\nmodel <- lm(x ~ y)\nsummary(model)\n```\n\nThese examples provide foundational insights into various endogeneity problems encountered during applied econometrics analyses. More sophisticated approaches---such as instrumental variables, fixed effects, or structural equation modeling---may be needed to tackle these challenges effectively in practical settings. \\## Collider Bias -- A Special Case of Endogeneity\n\nCollider bias, a subset of selection bias, occurs when conditioning on a variable, known as a collider, that is influenced by two or more other variables. This conditioning induces an association between these variables, even if they were independent initially.\n\n##Example 1: Stock Market Analysis - **Scenario**: Analyzing the relationship between a company's financial health and stock returns, considering market sentiment as a collider. Here is the R script to plot the DAG (Directed Acyclic Graph) for your scenario using the `dagitty` package:\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dagitty)\n\n# Define the DAG\ndag <- dagitty('dag {\n  Financial_Health -> Stock_Returns\n  Market_Sentiment -> Stock_Returns\n  Financial_Health -> Market_Sentiment\n}')\n\n# Plot the DAG\nplot(dag)\n```\n\n::: {.cell-output-display}\n![](colliderbias_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\nThis script defines a DAG where: - `Financial_Health` influences `Stock_Returns`. - `Market_Sentiment` also influences `Stock_Returns`. - `Financial_Health` affects `Market_Sentiment`.\n\nIn this DAG, `Market_Sentiment` is a collider on the path between `Financial_Health` and `Stock_Returns`. This means that conditioning on `Market_Sentiment` (e.g., through controlling or stratifying in a regression analysis) would open a backdoor path and potentially introduce bias in the estimation of the effect of `Financial_Health` on `Stock_Returns`. You can run this script in an R environment to visualize the DAG. It will help in understanding the causal relationships and in identifying potential sources of bias in your analysis.\n\nUnderstanding the implications of treating `Market Sentiment` as a collider in the context of your Directed Acyclic Graph (DAG) is crucial for causal inference and avoiding common statistical biases.\n\n::: \\### What is a Collider?\n\nA collider is a variable that is influenced by two or more other variables in a causal diagram or DAG. In your scenario, `Market Sentiment` is a collider because it is influenced by both `Financial Health` and `Stock Returns`.\n\n### Implications of Treating Market Sentiment as a Collider:\n\n1.  **Opening a Backdoor Path:** In DAGs, conditioning on a collider (like including it as a control variable in a regression model) opens a backdoor path. This can introduce bias into the estimation of causal effects. If you control for `Market Sentiment`, you inadvertently create a non-causal association between `Financial Health` and `Stock Returns` through the collider, leading to biased estimates.\n\n2.  **Spurious Correlation:** Controlling for `Market Sentiment` can create a spurious correlation between `Financial Health` and `Stock Returns`. Even if there is no direct causal link between these two variables, conditioning on the collider makes it seem like there is a relationship.\n\n3.  **Simpson's Paradox:** This is a phenomenon where a trend appears in different groups of data but disappears or reverses when these groups are combined. Controlling for `Market Sentiment` might show different relationships between `Financial Health` and `Stock Returns` in subgroups (e.g., high vs. low market sentiment), which could be misleading.\n\n4.  **Selection Bias:** If your analysis only includes data conditioned on certain values of the collider (e.g., only looking at times of positive market sentiment), this can lead to selection bias. The analysis might not be generalizable to all market conditions.\n\n5.  **Misinterpretation of Causal Effects:** Finally, including colliders in your model without proper understanding can lead to misinterpretation of causal effects. It can mask or inflate the true relationship between the variables of interest.\n\n### How to Handle Colliders:\n\n-   **Do Not Control for Colliders:** Unless you have a specific reason to do so, avoid controlling for colliders in your causal analyses.\n-   **Use DAGs for Model Specification:** DAGs can help you identify which variables to include or exclude from your models to avoid bias.\n-   **Consider Alternative Methods:** If it's essential to understand the impact of colliders, consider alternative statistical methods like stratification or structural equation modeling.\n\nIn summary, recognizing and appropriately handling colliders like `Market Sentiment` is vital for accurate causal inference. Misinterpreting or improperly controlling for such variables can lead to biased estimates and erroneous conclusions.\n\nFor further analysis, would you like to: - Explore alternative methods for dealing with colliders? - Delve into advanced causal inference techniques? - Discuss another aspect of econometric analysis or finance?\n\n## Simulating Endogeneity and Collider Bias\n\n-   **Python Implementation**: A Python code example demonstrating the simulation of endogeneity due to collider bias.\n-   **R Implementation**: An R code example showing how controlling for a collider can induce an artificial association in a regression model.\n\n## Practical Implications in Finance\n\nThis section discusses real-world scenarios in finance where endogeneity and collider bias play a significant role, such as in stock market analysis, credit risk assessment, and investment portfolio performance.\n\n## Mitigating Endogeneity and Collider Bias\n\n-   **Statistical Methods**: Discusses various statistical methods and techniques to detect and address endogeneity and collider bias.\n-   **Best Practices**: Offers best practices for econometric modeling to minimize the impact of these biases.\n\n#### Section 7: Conclusion\n\nSummarizes the key points of the chapter, emphasizing the importance of understanding and addressing endogeneity and collider bias in econometric analysis, especially in the field of finance.\n\n------------------------------------------------------------------------\n\n### Directed Acyclic Graphs (DAGs) for Key Concepts\n\n1.  **DAG for Stock Market Analysis**:\n    -   Nodes: Company's Financial Health (X1), Stock Returns (Y), Market Sentiment (Z), External Economic Conditions (X2).\n    -   Arrows: From X1 to Y, from X1 and X2 to Z.\n2.  **DAG for Credit Risk Assessment**:\n    -   Nodes: Borrower's Income (X1), Probability of Default (Y), Loan Amount (Z), Bank's Risk Policies (X2).\n    -   Arrows: From X1 to Y and Z, from X2 to Z.\n\nThese DAGs help visualize the relationships and potential biases in these scenarios, aiding in a better understanding of the concepts.\n\n------------------------------------------------------------------------\n\nFor further analysis, would you like to: - Explore more on DAGs and their role in econometrics? - Delve into advanced topics related to endogeneity and collider bias? - Discuss other econometric concepts relevant to financial analysis?",
    "supporting": [
      "colliderbias_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}