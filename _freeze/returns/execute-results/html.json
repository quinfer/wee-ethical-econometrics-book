{
  "hash": "b0180e6e4fa9c25d353a8c2ae006894c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Understanding Financial Data and Asset Returns\"\nauthor: \"Barry Quinn\"\neditor: visual\nbibliography: references.bib\n---\n\n\n\n\n\n\n![](images/logos/DALLÂ·E%202024-01-18%2016.32.37%20-%20Create%20a%20professional%20logo%20for%20an%20advanced%20financial%20data%20analytics%20course.%20The%20design%20should%20be%20vibrant,%20with%20a%20medium%20level%20of%20detail,%20balancing%20com.png){width=\"30%\" style=\"float: left; margin-right: 10px;\"}\n\nFinancial time series, such as asset prices, exchange rates, and interest rates, are fundamental in econometric analysis. Unlike prices, returns are more commonly used due to their desirable statistical properties, such as stationarity and scale independence. This chapter will explore various aspects of financial returns.\n\ng# We transform prices to returns\n\nIn financial econometrics, the focus on analyzing returns rather than prices is both theoretically and practically driven. Here's a detailed explanation based on the book @lo1997econometrics\n\n## Theoretical Reasons\n\n1.  **Stationarity**: Financial time series of prices are typically non-stationary, meaning their statistical properties (like mean and variance) change over time. This non-stationarity violates the basic assumptions of many econometric models. Returns, calculated as the percentage change in prices, are more likely to be stationary. Stationary data is crucial for applying many statistical and econometric techniques, as it ensures that the model's parameters are constant over time.\n\n2.  **Difficulties with Non-Stationary Data**: Working with non-stationary data can lead to spurious regression problems, where relationships between variables appear significant even when they are not. Returns typically exhibit weaker forms of non-stationarity compared to prices, reducing the risk of such misleading results.\n\n3.  **Economic Theory Alignment**: Returns represent the reward for bearing risk, which is a fundamental concept in financial economics. Analyzing returns aligns more closely with economic theories that focus on risk and reward, such as the Capital Asset Pricing Model (CAPM) and Efficient Market Hypothesis (EMH).\n\n4.  **Volatility Modeling**: Returns facilitate the modeling of volatility, a key aspect in financial markets. Models like GARCH (Generalized Autoregressive Conditional Heteroskedasticity) are designed to capture the volatility clustering often observed in returns, which is not as apparent when analyzing prices directly.\n\n## Transaction Costs\n\n1.  **Round Trip Transaction Costs**: This concept usually refers to the total costs incurred in completing a full investment cycle -- buying and then subsequently selling a financial asset. These costs include brokerage fees, bid-ask spreads, taxes, and other transaction expenses.\n\n2.  **Impact on Returns Analysis**: When considering round trip transaction costs in the context of financial markets, it's important to analyze returns rather than prices. This is because the actual return on an investment needs to account for these costs. For instance, even if an asset's price appreciates, the net return might be lower (or even negative) after accounting for transaction costs.\n\n3.  **Modeling and Risk Assessment**: In econometric models, incorporating transaction costs is crucial for realistic risk and return assessments. These costs can significantly impact the viability and attractiveness of trading strategies, especially those involving frequent transactions.\n\n4.  **Behavioral Implications**: Transaction costs also influence investor behavior. High costs might deter frequent trading, thereby affecting the liquidity and price volatility of assets.\n\n## Practical Reasons\n\n1.  **Comparability**: Returns standardize the performance across different assets, allowing for meaningful comparisons. For instance, a \\$5 increase in a \\$10 stock is a 50% return, whereas the same \\$5 increase in a \\$100 stock is only a 5% return. Analyzing prices would not capture this difference in performance.\n\n2.  **Simplicity in Modeling**: Modeling returns simplifies the mathematical complexity involved in dealing with non-stationary price series. This simplification allows for more straightforward interpretation and application of models.\n\n3.  **Risk Management**: In financial risk management, the focus is often on the variability of returns (i.e., risk) rather than absolute price levels. Analyzing returns directly aligns with this focus, aiding in the development of risk management strategies.\n\n4.  **Efficient Market Considerations**: In efficient markets, it is believed that all available information is already reflected in current prices. Therefore, the focus is on changes in prices (returns), which reflect new information, rather than on the price levels themselves.\n\n# Asset Returns\n\n## One-Period Simple Returns\n\nSimple returns represent the percentage change in asset price over a single period and are calculated as follows:\n\n$$ R_t = \\frac{P_t - P_{t-1}}{P_{t-1}} $$\n\nwhere ( R_t ) is the return at time ( t ), ( P_t ) is the price at time ( t ), and ( P\\_{t-1} ) is the price at time ( t-1 ).\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tsfe)\n# Assuming 'prices' is a vector of asset prices\nprices<-monte_carlo_paths()\nprices<-filter(prices, possible_path_no==1)\n\nreturns <- na.omit(diff(prices$sample_path)) / lag(prices$sample_path, 1)\nreturns <- na.omit(returns)\n```\n:::\n\n\n\n\n\n\n## Multiperiod Simple Returns\n\nFor multiple periods, simple returns are compounded. The formula for a return over ( n ) periods is:\n\n$$ R_{t, t+n} = \\prod_{i=1}^{n} (1 + R_{t+i}) - 1 $$\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# To calculate multiperiod returns\nmultiperiod_return <- prod(1 + returns) - 1\n```\n:::\n\n\n\n\n\n\n## Time Interval Considerations\n\nThe time interval of returns (daily, monthly, yearly) significantly impacts their magnitude and volatility. Annualizing returns involves scaling them to a yearly basis, usually by multiplying (for simple returns) or exponentiation (for log returns) by the number of periods per year.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndaily_return <- returns\n# Annualizing daily returns (assuming 252 trading days in a year)\nannualized_return <- (1 + daily_return) ^ 252 - 1\n```\n:::\n\n\n\n\n\n\n## Continuously Compounded Returns\n\nContinuously compounded, or log returns, are computed as the natural logarithm of the price ratio:\n\n$$ r_t = \\ln\\left(\\frac{P_t}{P_{t-1}}\\right) $$\n\nLog returns are time-additive, making them suitable for multi-period returns calculation and econometric modeling.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlog_returns <- diff(log(prices$sample_path))\nlog_returns <- na.omit(log_returns)\n```\n:::\n\n\n\n\n\n\n## Portfolio Returns\n\nPortfolio returns are the weighted average of individual asset returns, reflecting the portfolio composition.\n\n### Simple Portfolio Returns\n\nThe simple return of a portfolio is the sum of the weighted returns of each asset.\n\n$$ R_{portfolio} = \\sum_{i=1}^{N} w_i R_i $$\n\nwhere ( w_i ) is the weight of the ( i\\^{th} ) asset in the portfolio, and ( R_i ) is its return.\n\n``` r\n# Assuming 'weights' is a vector of portfolio weights and 'returns' is a matrix of returns\nportfolio_return <- rowSums(weights * returns)\n```\n\n### Log Portfolio Returns\n\nFor log returns, the portfolio return is not a simple weighted sum but can be approximated for small individual returns.\n\n## Adjustments for Dividend Payments\n\nTotal return, considering both price changes and dividends, gives a more complete picture of an asset's performance.\n\n$$ R_{total} = \\frac{P_t + D_t - P_{t-1}}{P_{t-1}} $$\n\nwhere ( D_t ) is the dividend paid at time ( t ).\n\n## Excess Returns\n\nExcess return is the return of an asset over and above a benchmark or risk-free rate, crucial in risk-adjusted performance analysis.\n\n$$ R_{excess} = R_{asset} - R_{benchmark} $$\n\n## Bond Yields and Prices\n\nHere is an expansion of the Bond Yields and Prices section with more details and examples on the sub-topics:\n\n## Bond Yields and Prices\n\nBonds are debt instruments issued by governments, municipalities, and corporations to raise capital. Key bond features include:\n\n### Coupon Rate\n\nThe coupon rate is the periodic interest rate paid on the par value, typically semiannually. It represents an annual percentage yield to the investor based on invested capital. Coupon payments are calculated as:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npv <- 100  \ncpn <- 0.05\ncpn_payment <- pv * cpn  \nprint(cpn_payment)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5\n```\n\n\n:::\n:::\n\n\n\n\n\n\n### Maturity Date\n\nThe maturity date determines the bond's term or tenor. Longer-dated bonds generally pay higher yields to compensate investors for reduced liquidity and higher interest rate risk over time. Maturity also impacts the relationship between price and yield.\n\n### Factors Impacting Yields\n\nSeveral factors determine the base yield investors demand on bonds:\n\n**Credit Risk** - Probability that principal and interest will not be repaid as obligated. Lower rated bonds offer higher yields to offset higher default risk.\n\n**Time to Maturity** - As discussed, longer maturities require higher yields.\n\n**Tax Treatment** - Tax exemptions for municipal bonds allow them to pay lower pre-tax yields.\n\n**Liquidity** - Easier tradability allows lower yields to compensate for reduced risk.\n\n**Interest Rates** - Prevailing rates determine a baseline for yield levels across bonds.\n\nFor example, 10-year BBB corporate bonds currently offer higher yields than 10-year Treasuries due to higher credit risk:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(quantmod)  \n\ncorp_ytm <- 0.049  # 4.9% YTM\ntbill_ytm<- 0.038   # 3.8% YTM \n\nprint(paste0(\"Corporate Bond Premium = \", round(100*(corp_ytm - tbill_ytm), 2), \" basis points\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Corporate Bond Premium = 1.1 basis points\"\n```\n\n\n:::\n:::\n\n\n\n\n\n\n### Bond Categories\n\nSure, here is an expansion on the different bond categories:\n\n### Bond Categories\n\nThere are a few major categories of bonds:\n\n**Treasury Bonds** - Issued by the federal government and considered essentially default risk-free. Treasuries make up the largest single debt market and serve benchmark pricing and yield roles. Different types are distinguished by maturity:\n\n-   Treasury bills - Maturities less than 1 year\n-   Treasury notes - 2 to 10 year maturities\n-   Treasury bonds - Over 10 years\n\n**Municipal Bonds** - Issued by state and local governments to finance public infrastructure projects. Key features include tax exemption and thus lower yields along with higher default risk than federal government:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Taxable equivalent yield\ntax_rate <- 0.3\ntax_exempt_yield <- 0.02  \n\nequivalent_taxable_yield <- tax_exempt_yield / (1 - tax_rate) \nequivalent_taxable_yield\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.02857143\n```\n\n\n:::\n:::\n\n\n\n\n\n\n**Corporate Bonds** - Debt issued by corporations and are categorized by credit ratings. Investment-grade bonds (BBB-or higher rating) offer modest yields while high-yield \"junk\" bonds pay much higher yields due to elevated default risk.\n\n**Mortgage Bonds** -- Debt collateralized by pools of mortgage loans with interest and principal used to make payments.\n\nIn terms of total volume outstanding in the US, Treasury and corporate bonds have the greatest market size followed by mortgage-related and municipal securities. Understanding differences across bond categories assists with portfolio allocation and relative value comparisons.\n\n## Implied Volatility\n\nHere is an expanded Implied Volatility section with more details and R code examples:\n\n## Implied Volatility\n\nVolatility measures how rapidly an asset's price moves. It is a key input in options pricing models.\n\n### Options Pricing Basics\n\nOptions give holders the right, but not the obligation, to buy or sell the underlying asset by the expiration date at a pre-determined price (strike price). In return, buyers pay an upfront premium. Two types exist:\n\n-   **Call Options:** Right to buy the asset\n-   **Put Options:** Right to sell the asset\n\nFor instance, a stock call option may have a \\$100 strike with \\$5 premium.\n\nThe classic Black-Scholes formula prices options based on current stock price, strike price, volatility, risk-free rate, and time to expiration.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Black-Scholes Call Option Example\nS <- 100     # Asset price  \nK <- 100     # Strike price\nsigma <- 0.3 # Volatility \nr <- 0.01    # Risk-free rate  \nt <- 1       # Years til expiration  \n\nd1 <- (log(S/K)+(r+sigma^2/2)*t) / (sigma*sqrt(t))  \nd2 <- d1 - sigma*sqrt(t)\ncall_price <- S * pnorm(d1) - K * exp(-r * t) * pnorm(d2)\n\nprint(paste(\"Call Price:\", round(call_price, 2)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Call Price: 12.37\"\n```\n\n\n:::\n:::\n\n\n\n\n\n\n### Implied Volatility\n\nRather than estimating volatility based on historical prices, implied volatility uses the known market price and inverts the options pricing model to solve for volatility. It represents the market's forward-looking expectation of volatility over the option's life.\n\n``` r\nlibrary(tsfe)\n# Market parameters\nS <- 100 # Current stock price\nK <- 100 # Strike price\nT <- 1 # Time to maturity in years\nr <- 0.05 # Risk-free interest rate\nq <- 0 # Dividend yield\nmarket_price <- 4 # Actual call price observed in the market\n\n# Calculate implied volatility using the BlackScholes function from MyFinancePackage\nimplied_vol <- uniroot(function(x) BlackScholes(\"call\", S, K, T, r, x, q) - market_price, interval = c(0.01, 5))$root\n\nprint(paste(\"Implied Volatility:\", round(implied_vol * 100, 2), \"%\"))\n```\n\n### Explanation:\n\n-   **BlackScholes Function**: This function is defined to calculate the price of a call option based on the Black-Scholes model. It takes the current stock price (`S0`), strike price (`K`), time to maturity (`T`), risk-free interest rate (`r`), volatility (`sigma`), and dividend yield (`q`) as inputs.\n\n-   **Market Parameters**: These variables represent the conditions under which you're trying to find the implied volatility. `S` is the current stock price, `K` is the strike price, `T` is the time to expiration in years, `r` is the risk-free interest rate, and `q` is the dividend yield. `market_price` is the observed market price of the call option.\n\n-   **Implied Volatility Calculation**: The `uniroot` function finds the volatility value that, when used in the `BlackScholes` function, results in the option price matching the market price of the call option. The `interval = c(0.01, 5)` argument specifies the search interval for the volatility (from 1% to 500%). Adjust this interval based on your market expectations and the typical volatility range of the underlying asset.\n\n-   **Print Statement**: Finally, the calculated implied volatility is printed out as a percentage with two decimal places.\n\nComparing implied volatility vs. historical volatility shows when options may be relatively expensive or cheap based on realized volatility. The CBOE Volatility Index (VIX) takes this concept further by aggregating implied volatility across S&P 500 index options to measure broad market volatility expectations.\n\n### CBOE Volatility Index (VIX)\n\nThe VIX represents the market's consensus expectation for S&P 500 volatility over the next 30 days based on SPX option prices. Known as the \"fear gauge,\" it enables trading volatility directly:\n\n```         \n# Calculate VIX based on SPX option prices\nspx_calls <- getOptionChain(\"SPX\") \ncall_prices <- spx_calls$lastPrice  \n\nvix <- variance_swap(log(call_prices), spx_calls$strike, \n                     S0=mean(spx_calls$strike), ttm=30/365)\nprint(paste(\"VIX:\", round(100*sqrt(vix), 2)))\n```\n\nRather than a direct index, the VIX allows trading volatility expectations through VIX futures contracts and VIX-linked ETFs and ETNs. Monitoring the VIX shows when traders anticipate unstable markets compared to realized volatility. Comparing VIX levels to historical averages provides context on volatility regime shifts.\n\n# Overlapping Returns and Autocorrelation\n\nA common approach in empirical asset pricing research involves using time-series data of asset returns. For example, a researcher may collect daily stock return data over several years to study predictive signals, risk factors, or other relationships. However, the use of overlapping multiperiod returns can introduce statistical complications @lo1990econometric.\n\nThe issue arises because adjacent return observations share common days, inducing autocorrelation in the time-series data. For instance, 20-day returns with a 1-day shift comprise 19 identical daily returns. This overlap across return intervals leads to spurious correlation, violating assumptions of independently and identically distributed (i.i.d) observations under classical statistical models.\n\nConsequences include biased coefficient estimates, understated standard errors, and over-rejection of null hypotheses during hypothesis testing. In effect, the observed sample size overstates the effective size for calculating precision and confidence levels. The series appears to contain more information than is actually present.\n\nConsider the simulated autocorrelated return process:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)  \nr <- arima.sim(model=list(ar=0.5), n=100)\nacf(r)  \n```\n\n::: {.cell-output-display}\n![](returns_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nRegressing another random series x onto r yields biased estimates and t-stats:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- rnorm(100) \ny <- x + r + rnorm(100)\nsummary(lm(y ~ x))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.8639 -0.8560  0.0053  1.0721  3.8671 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   0.2624     0.1483   1.769     0.08 .  \nx             0.9920     0.1483   6.687 1.41e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.483 on 98 degrees of freedom\nMultiple R-squared:  0.3133,\tAdjusted R-squared:  0.3063 \nF-statistic: 44.72 on 1 and 98 DF,  p-value: 1.407e-09\n```\n\n\n:::\n:::\n\n\n\n\n\n\nThere are several potential approaches for handling overlapping data:\n\n1.  Utilize non-overlapping returns - e.g. annual instead of monthly. This eliminates overlap bias but reduces sample size considerably.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr<-tibble(r)\nslices<-seq(1, nrow(r), 12)\nr_annual <- r |> slice(slices)   \n```\n:::\n\n\n\n\n\n\n2.  Model the autocorrelation structure like an ARMA process. Specify this correlation during estimation for properly adjusted estimates and standard errors. However, this relies on correctly specifying the autocorrelation structure.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nar1 <- arima(y, xreg=x, order=c(1,0,0))  \n```\n:::\n\n\n\n\n\n\n3.  Employ statistical techniques robust to certain autocorrelation structures, such as heteroskedasticity and autocorrelation (HAC) corrections to standard errors. For example, Newey-West standard errors.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lmtest)\nlibrary(sandwich) \nr <- arima.sim(model=list(ar=0.5), n=100)\nx <- rnorm(100)\ny <- x + r + rnorm(100)\n\nmod <- lm(y ~ x)\n\ncoeftest(mod, vcov = NeweyWest(mod))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nt test of coefficients:\n\n            Estimate Std. Error t value  Pr(>|t|)    \n(Intercept) 0.057822   0.191822  0.3014    0.7637    \nx           0.973118   0.125354  7.7629 8.101e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n\n\nOverlapping returns has relevance in many empirical finance settings but warrants additional consideration during econometric modeling and analysis. Failing to account for the induced autocorrelation can undermine results and conclusions. For example, @richardson1991tests investigate daily stock return regressions and find that positive autocorrelation from overlapping intervals can falsely indicate significant predictability when the true process contains only white noise.\n\n## References",
    "supporting": [
      "returns_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}